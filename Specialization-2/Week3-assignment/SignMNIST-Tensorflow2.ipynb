{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports \n",
    "import math\n",
    "import numpy as np \n",
    "import h5py\n",
    "import matplotlib.pyplot as plt \n",
    "import tensorflow as tf \n",
    "from dataloader import *\n",
    "from tensorflow import keras\n",
    "\n",
    "%matplotlib inline \n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading and preparation\n",
    "\n",
    "- Load the data \n",
    "- Flatten the image.\n",
    "- Normalize the image vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data \n",
    "X_train_orig, Y_train_orig, X_test_orig, Y_test_orig, classes = load_dataset()\n",
    "\n",
    "# Flatten the image \n",
    "X_train_flatten = X_train_orig.reshape(X_train_orig.shape[0], -1).T\n",
    "X_test_flatten = X_test_orig.reshape(X_test_orig.shape[0], -1).T\n",
    "\n",
    "# Normalize these vectors \n",
    "X_train = X_train_flatten/255\n",
    "X_test = X_test_flatten/255\n",
    "\n",
    "# convert Y_train to one hot matrix using tensorflow\n",
    "Y_train = convert_to_one_hot(Y_train_orig, 6)\n",
    "Y_test = convert_to_one_hot(Y_test_orig, 6)\n",
    "\n",
    "layer_dims = [12288, 25, 12, 6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize parameters with Xavier initialization \n",
    "\n",
    "def initialize_parameters(layer_dims):\n",
    "    \n",
    "    \"\"\"\n",
    "    layer dims = X_train.Shape[0], 25, 12, 6\n",
    "    \"\"\"\n",
    "    tf.random.set_seed(1)\n",
    "    parameters = {}\n",
    "    L = len(layer_dims)\n",
    "    \n",
    "    for l in range(1, L):\n",
    "        w = tf.Variable(tf.initializers.GlorotUniform()(dtype=tf.float64, shape=(layer_dims[l], layer_dims[l-1])))\n",
    "        b = tf.Variable(tf.zeros(dtype=tf.float64, shape=(layer_dims[l], 1)))\n",
    "        \n",
    "        #insert in dict \n",
    "        parameters[\"W\" + str(l)] = w\n",
    "        parameters[\"b\" + str(l)] = b\n",
    "        \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward porpagtion in tensorflow \n",
    "def forward_propagation(X, parameters):\n",
    "    \n",
    "    # Retrieve the parameters from the dictionary \"parameters\" \n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    W3 = parameters['W3']\n",
    "    b3 = parameters['b3']\n",
    "    \n",
    "    Z1 = tf.add(tf.matmul(W1,X), b1)                          \n",
    "    A1 = tf.nn.relu(Z1)                                       \n",
    "    Z2 = tf.add(tf.matmul(W2,A1), b2)                         \n",
    "    A2 = tf.nn.relu(Z2)                                       \n",
    "    Z3 = tf.add(tf.matmul(W3,A2), b3) \n",
    "    \n",
    "    return Z3\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute cost \n",
    "def compute_cost(Z3, Y):\n",
    "    \n",
    "    logits = tf.transpose(Z3)\n",
    "    labels = tf.transpose(Y)\n",
    "    \n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = logits, labels = labels))\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X_train, Y_train, X_test, Y_test, learning_rate = 0.0001,\n",
    "          num_epochs = 1500, minibatch_size = 32, print_cost = True):\n",
    "    \n",
    "    layer_dims = [12288, 25, 12, 6]\n",
    "    tf.random.set_seed(1)\n",
    "    seed = 3\n",
    "    (n_x, m) = X_train.shape\n",
    "    n_y = Y_train.shape[0]\n",
    "    costs = []\n",
    "    \n",
    "    # init parameters \n",
    "    parameters = initialize_parameters(layer_dims)\n",
    "    \n",
    "    # forward prop\n",
    "    Z3 = forward_propagation(X_train, parameters)\n",
    "    \n",
    "    #cost calculation\n",
    "    cost = compute_cost(Z3,Y_train)\n",
    "    \n",
    "    # backprop\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate, \n",
    "                                         beta_1=0.9, beta_2=0.999, epsilon=1e-07)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1.807944063922447, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "parameters = initialize_parameters(layer_dims)\n",
    "Z3 = forward_propagation(X_train, parameters)\n",
    "cost = compute_cost(Z3, Y_train)\n",
    "print(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
