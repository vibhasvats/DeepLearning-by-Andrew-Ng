{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "from dataloader import * \n",
    "from testCases import * \n",
    "import h5py\n",
    "\n",
    "%matplotlib inline \n",
    "plt.rcParams[\"figure.figsize\"] = (7.0, 4.0) \n",
    "plt.rcParams[\"image.interpolation\"] = 'nearest'\n",
    "plt.rcParams[\"image.cmap\"] = 'gray'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All needed functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sigmoid \n",
    "def sigmoid(x):\n",
    "    s = 1/(1 + np.exp(-x))\n",
    "    return s \n",
    "\n",
    "# ReLu\n",
    "def relu(x): \n",
    "    s = np.maximum(0, x)\n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize parameters \n",
    "def initialize_parameters(layer_dims):\n",
    "    \n",
    "    \n",
    "    # to keep the output same \n",
    "    np.random.seed(3)\n",
    "    parameters = {}\n",
    "    L = len(layer_dims)\n",
    "    \n",
    "    for l in range(1,L):\n",
    "        parameters[\"W\" + str(l)] = np.random.randn(layer_dims[l], layer_dims[l-1])/np.sqrt(layer_dims[l-1])\n",
    "        parameters[\"b\" + str(l)] = np.zeros((layer_dims[l], 1))\n",
    "        \n",
    "        assert(parameters[\"W\" + str(l)].shape == (layer_dims[l], layer_dims[l-1]))\n",
    "        assert(parameters[\"b\" + str(l)].shape == (layer_dims[l],1))\n",
    "        \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## forward propagation \n",
    "def forward_propagation(X, parameters):\n",
    "    \n",
    "    # retrieve parameters \n",
    "    W1 = parameters[\"W1\"]\n",
    "    b1 = parameters[\"b1\"]\n",
    "    W2 = parameters[\"W2\"]\n",
    "    b2 = parameters[\"b2\"]\n",
    "    W3 = parameters[\"W3\"]\n",
    "    b3 = parameters[\"b3\"]\n",
    "    \n",
    "    # forward calculation \n",
    "    Z1 = np.dot(W1,X) + b1\n",
    "    A1 = relu(Z1)\n",
    "    Z2 = np.dot(W2, A1) + b2\n",
    "    A2 = relu(Z2)\n",
    "    Z3 = np.dot(W3, A2) + b3 \n",
    "    A3 = sigmoid(Z3)\n",
    "    \n",
    "    cache = (Z1, A1, W1, b1, Z2, A2, W2, b2 ,Z3, A3, W3, b3)\n",
    "    \n",
    "    return A3, cache\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backward propagation \n",
    "def backward_propagation(X, Y, cache):\n",
    "    \n",
    "    m = X.shape[1]\n",
    "    (Z1, A1, W1, b1, Z2, A2, W2, b2 ,Z3, A3, W3, b3) = cache\n",
    "    \n",
    "    dZ3 = A3 - Y\n",
    "    dW3 = (1./m)*np.dot(dZ3, A2.T)\n",
    "    db3 = (1./m)*np.sum(dZ3, axis=1, keepdims=True)\n",
    "    \n",
    "    dA2 = np.dot(W3.T, dZ3)\n",
    "    dZ2 = np.multiply(dA2, np.int64(A2 > 0))\n",
    "    dW2 = (1./m)*np.dot(dZ2,A1.T)\n",
    "    db2 = (1./m)*np.sum(dZ2, axis=1, keepdims=True)\n",
    "    \n",
    "    dA1 = np.dot(W2.T, dZ2)\n",
    "    dZ1 = np.multiply(dA1, np.int64(A1>0))\n",
    "    dW1 = (1./m)*np.dot(dZ1, X.T)\n",
    "    db1 = (1./m)*np.sum(dZ1, axis=1, keepdims=True)\n",
    "    \n",
    "    gradients = {\"dZ3\": dZ3, \"dW3\": dW3, \"db3\": db3,\n",
    "                 \"dA2\": dA2, \"dZ2\": dZ2, \"dW2\": dW2, \"db2\": db2,\n",
    "                 \"dA1\": dA1, \"dZ1\": dZ1, \"dW1\": dW1, \"db1\": db1}\n",
    "    \n",
    "    return gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update parameters \n",
    "def update_parameters(parameters, grads, learning_rate):\n",
    "    \n",
    "    # L number of layers of neural network \n",
    "    L = len(parameters)//2\n",
    "    \n",
    "    # update rule \n",
    "    for l in range(L): \n",
    "        parameters[\"W\" + str(l+1)] = parameters[\"W\" + str(l+1)] - learning_rate*grads[\"dW\" + str(l + 1)]\n",
    "        parameters[\"b\" + str(l+1)] = parameters[\"b\" + str(l+1)] - learning_rate*grads[\"db\" + str(l + 1)]\n",
    "        \n",
    "    return parameters\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction \n",
    "def predict(X, y, parameters):\n",
    "    \n",
    "    m = X.shape[1]\n",
    "    p = np.zeros((1,m), dtype = np.int)\n",
    "    \n",
    "    # forward propagation \n",
    "    a3, caches = forward_propagation(X, parameters)\n",
    "    \n",
    "    # convert probabilities to 0/1 predictions\n",
    "    p[a3 > 0.5] = 1\n",
    "    \n",
    "    # accuracy \n",
    "    print(\"Accuracy:\" + str(np.mean((p[0,:] == y[0,:]))))\n",
    "    \n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute cost \n",
    "def compute_cost(a3,Y):\n",
    "    m = Y.shape[1]\n",
    "    logprobs = np.multiply(-np.log(a3), Y) + np.multiply(-np.log(1 - a3), (1-Y))\n",
    "    cost = (1./m)*np.nansum(logprobs)\n",
    "    \n",
    "    return cost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading dataset \n",
    "def load_dataset(): \n",
    "    train_dataset = h5py.File('datasets/train_catvnoncat.h5', \"r\")\n",
    "    train_set_x_orig = np.array(train_dataset[\"train_set_x\"][:])\n",
    "    train_set_y_orig = np.array(train_dataset[\"train_set_y\"][:])\n",
    "    \n",
    "    test_dateset = h5py.File('datasets/test_catvnoncat.h5', \"r\")\n",
    "    test_set_x_orig = np.array(test_dateset[\"test_set_x\"][:])\n",
    "    test_set_y_orig = np.array(test_dateset[\"test_set_y\"][:])\n",
    "    \n",
    "    classes = np.array(test_dateset[\"list_classes\"][:])\n",
    "    \n",
    "    train_set_y = train_set_y_orig.reshape((1,train_set_y_orig.shape[0]))\n",
    "    test_set_y = test_set_y_orig.reshape((1, test_set_y_orig.shape[0]))\n",
    "    \n",
    "    train_set_x_orig = train_set_x_orig.reshape(train_set_x_orig.shape[0], -1).T\n",
    "    test_set_x_orig = test_set_x_orig.reshape(test_set_x_orig.shape[0], -1).T\n",
    "    \n",
    "    train_set_x = train_set_x_orig/ 255\n",
    "    test_set_x = test_set_x_orig/255\n",
    "    \n",
    "    return train_set_x, train_set_y, test_set_x, test_set_y, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict_dec \n",
    "def predict_dec(parameters, X):\n",
    "    \n",
    "    a3, cache = forward_propagation(X, parameters)\n",
    "    prediction = (a3 > 0.5)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# implementing different models \n",
    "\n",
    "* we will implement three different models \n",
    "    - non regularized model \n",
    "    - L2 regularized model \n",
    "    - Drop out regularized model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-regularized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# non-regularized model \n",
    "def model(X, Y, learning_rate=0.3, num_iteration=30000, print_cost=True, lambd=0, keep_prob=1):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_Y, test_X, test_Y = load_2D_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
